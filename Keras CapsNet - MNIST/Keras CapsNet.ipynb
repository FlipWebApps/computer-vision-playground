{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras CapsNet MNIST\n",
    "\n",
    "Examples of image recognition on the MNIST dataset using Keras using CapsNet.\n",
    "\n",
    "Caps note code is adapted from: https://github.com/XifengGuo/CapsNet-Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "#from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "from keras import layers, models, optimizers\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some shared functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, X_test, y_test):\n",
    "    \"\"\" \n",
    "    Evaluate and show a models scores \n",
    "    \n",
    "    Args: \n",
    "        model: The model to score \n",
    "        X_test: test set\n",
    "        y_test: labels for the test set\n",
    "        \n",
    "    Returns: \n",
    "    \n",
    "    \"\"\"\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print(\"Baseline Error: %.2f%%\" % (100-score[1]*100))\n",
    "\n",
    "def plot_model_accuracy_loss(history):\n",
    "    \"\"\" \n",
    "    Show plots of train v's test accuracy and loss. \n",
    "    \n",
    "    Args: \n",
    "        history: history returned from fitting a model \n",
    "        \n",
    "    Returns: \n",
    "    \n",
    "    \"\"\"\n",
    "    # summarize history for accuracy  \n",
    "    plt.subplot(211)  \n",
    "    plt.plot(history.history['acc'])  \n",
    "    plt.plot(history.history['val_acc'])  \n",
    "    plt.title('model accuracy')  \n",
    "    plt.ylabel('accuracy')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'test'], loc='upper left')  \n",
    "   \n",
    "    # summarize history for loss     \n",
    "    plt.subplot(212)  \n",
    "    plt.plot(history.history['loss'])  \n",
    "    plt.plot(history.history['val_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'test'], loc='upper left')  \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plot_sample_predictions(model, X_test, X_test_reshaped, y_test):\n",
    "    \"\"\" \n",
    "    Show plots of sample predictions \n",
    "    \n",
    "    Args: \n",
    "        model: The model to evaluate \n",
    "        X_test: test set\n",
    "        X_test_reshaped: test set reshaped if needed for the model\n",
    "        y_test: labels for the test set\n",
    "        \n",
    "    Returns: \n",
    "    \n",
    "    \"\"\"\n",
    "    # The predict_classes function outputs the highest probability class# The pr \n",
    "    # according to the trained classifier for each input example.\n",
    "    predicted_classes = model.predict_classes(X_test_reshaped)\n",
    "    \n",
    "    # Show some items we got right\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    plt.suptitle('Samples of Correct Predictions', fontsize=\"x-large\")\n",
    "    correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
    "    for i, correct in enumerate(correct_indices[:9]):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "        plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\n",
    "    # shift subplots down:\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "    \n",
    "    # Show some items we got wrong\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    plt.suptitle('Samples of Incorrect Predictions', fontsize=\"x-large\")\n",
    "    incorrect_indices = np.nonzero(predicted_classes != y_test)[0]\n",
    "    for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "        plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))\n",
    "    # shift subplots down:\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the mnist data and show a few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(8, 8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.title(\"Class {}\".format(y_train[i]))\n",
    "    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values are gray scale between 0 and 255. It is almost always a good idea to perform some scaling of input values when using neural network models. Because the scale is well known and well behaved, we can very quickly normalize the pixel values to the range 0 and 1 by dividing each value by the maximum of 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the output variable is an integer from 0 to 9. As this is a multi-class classification problem we need to one hot encoding of the class values, transforming the vector of class integers into a binary matrix.\n",
    "\n",
    "We can easily do this using the built-in np_utils.to_categorical() helper function in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n",
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "(60000, 10)\n",
      "(10000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs and save original classes\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train[:10])\n",
    "y_train_classes = y_train.copy()\n",
    "y_test_classes = y_test.copy()\n",
    "y_train = np_utils.to_categorical(y_train_classes)\n",
    "y_test = np_utils.to_categorical(y_test_classes)\n",
    "num_classes = y_test.shape[1]\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is structured as a 3-dimensional array of (instance, image width and image height). Our neural-network is going to take a single vector for each training example, so we need to reshape the input so that each 28x28 image becomes a single 784 dimensional vector.\n",
    "\n",
    "We can do this transform easily using the reshape() function on the NumPy array. We can also reduce our memory requirements by forcing the precision of the pixel values to be 32 bit, the default precision used by Keras anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a CapsNet - code from https://github.com/XifengGuo/CapsNet-Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapsNet(input_shape, n_class, routings):\n",
    "   \"\"\"\n",
    "   A Capsule Network on MNIST.\n",
    "   :param input_shape: data shape, 3d, [width, height, channels]\n",
    "   :param n_class: number of classes\n",
    "   :param routings: number of routing iterations\n",
    "   :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
    "   `eval_model` can also be used for training.\n",
    "   \"\"\"\n",
    "   x = layers.Input(shape=input_shape)\n",
    "\n",
    "   # Layer 1: Just a conventional Conv2D layer\n",
    "   conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "   # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "   primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "   # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "   digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "   name='digitcaps')(primarycaps)\n",
    "\n",
    "   # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "   # If using tensorflow, this will not be necessary. :)\n",
    "   out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "   # Decoder network.\n",
    "   y = layers.Input(shape=(n_class,))\n",
    "   masked_by_y = Mask()([digitcaps, y]) # The true label is used to mask the output of capsule layer. For training\n",
    "   masked = Mask()(digitcaps) # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "   # Shared Decoder model in training and prediction\n",
    "   decoder = models.Sequential(name='decoder')\n",
    "   decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
    "   decoder.add(layers.Dense(1024, activation='relu'))\n",
    "   decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "   decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "   # Models for training and evaluation (prediction)\n",
    "   train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "   eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "   # manipulate model\n",
    "   noise = layers.Input(shape=(n_class, 16))\n",
    "   noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "   masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "   manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "   return train_model, eval_model, manipulate_model\n",
    "\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "   \"\"\"\n",
    "   Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "   :param y_true: [None, n_classes]\n",
    "   :param y_pred: [None, num_capsule]\n",
    "   :return: a scalar loss value.\n",
    "   \"\"\"\n",
    "   L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "   0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "   return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Development\\DataScience\\Learning\\DataScience\\ComputerVision\\Keras CapsNet - MNIST\\capsulelayers.py:145: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 20, 20, 256)  20992       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv2d (Conv2D)      (None, 6, 6, 256)    5308672     conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 1152, 8)      0           primarycap_conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 1152, 8)      0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "digitcaps (CapsuleLayer)        (None, 10, 16)       1474560     primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_1 (Mask)                   (None, 160)          0           digitcaps[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Length)                (None, 10)           0           digitcaps[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 28, 28, 1)    1411344     mask_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,215,568\n",
      "Trainable params: 8,215,568\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, eval_model, manipulate_model = CapsNet(input_shape=X_train.shape[1:],\n",
    " n_class=len(np.unique(np.argmax(y_train, 1))),\n",
    " routings=3)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001),\n",
    " loss=[margin_loss, 'mse'],\n",
    " loss_weights=[1., 0.392],\n",
    " metrics={'capsnet': 'accuracy' : 'out_caps'})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup callback for tensor board logging, saving weights and early stopping. To start tensorboard, change to the folder containing the logs directory and run:\n",
    "\n",
    "tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "tf_callback= TensorBoard(log_dir=\"logs/keras_capsnet/{}\".format(time()), \n",
    "                                            histogram_freq=1, write_graph=True, write_images=True)\n",
    "checkpointer = ModelCheckpoint(filepath='Keras CapsNet.Model.Best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-94cee3e5f9ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m history = model.fit_generator(generator=train_generator(X_train, y_train, 1000, 0.1),\n\u001b[0;32m     11\u001b[0m                                      \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                                      verbose=2, callbacks=[tf_callback, checkpointer, earlystopping])\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_generator(x, y, batch_size, shift_fraction=0.1):\n",
    "    train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "    height_shift_range=shift_fraction) # shift up to 2 pixel for MNIST\n",
    "    generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "    while 1:\n",
    "        x_batch, y_batch = generator.next()\n",
    "        yield ([x_batch, y_batch], [y_batch, x_batch])\n",
    "\n",
    "# Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
    "history = model.fit_generator(generator=train_generator(X_train, y_train, 1000, 0.1),\n",
    "                              steps_per_epoch=int(y_train.shape[0] / 1000), epochs=5,\n",
    "                              validation_data=[[X_test, y_test], [y_test, X_test]],\n",
    "                              verbose=2, callbacks=[tf_callback, checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load back in the best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Keras CapsNet.Model.Best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot accuracy and loss for train / test sets to see if more epochs would have helped and to ensure that we don't start overfitting.\n",
    "\n",
    "Here we should probably have stopped after 4 epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_model_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the output\n",
    "Manually inspect the output to check everything looks as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_sample_predictions(model, X_test, X_test, y_test_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
