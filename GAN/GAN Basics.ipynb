{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator of a GAN needs to translate from coarse salient features to a more dense and detailed output (typically an image). I.e. a kind of 'inverse' to pooling layers.\n",
    "\n",
    "NOTE: Move to cnn-basics?\n",
    "\n",
    "references: https://machinelearningmastery.com/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UpSampling2D\n",
    "By default UpSampling2D uses a nearest neighbor algorithm to fill in the new rows and columns effectively duplicating points. (‘interpolation‘ argument = ‘nearest‘). Bilinear interpolation can be specified via setting the ‘interpolation‘ argument to ‘bilinear‘ e.g. UpSampling2D(interpolation='bilinear').\n",
    "\n",
    "Subsequent convolution layers will be trained to interpret the upsampled output and translate it into meaningful detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "up_sampling2d_3 (UpSampling2 (None, 4, 4, 1)           0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[1. 1. 2. 2.]\n",
      " [1. 1. 2. 2.]\n",
      " [3. 3. 4. 4.]\n",
      " [3. 3. 4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# example of using the upsampling layer\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import UpSampling2D\n",
    "\n",
    "# define input data\n",
    "X = asarray([[1, 2],\n",
    "             [3, 4]])\n",
    "\n",
    "# show input data for context\n",
    "print(X)\n",
    "\n",
    "# reshape input data into one sample a sample with a channel\n",
    "X = X.reshape((1, 2, 2, 1))\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(UpSampling2D(input_shape=(2, 2, 1), size=(2,2)))\n",
    "\n",
    "# summarize the model\n",
    "model.summary()\n",
    "\n",
    "# make a prediction with the model\n",
    "yhat = model.predict(X)\n",
    "\n",
    "# reshape output to remove channel to make printing easier\n",
    "yhat = yhat.reshape((4, 4))\n",
    "\n",
    "# summarize output\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2DTranspose \n",
    "Conv2DTranspose performs an inverse convolution operation and thus is similar to combining the UpSampling2D and Conv2D layers into one layer in that it simultaneously upsamples and learns how to interpret the result. This is typically preferred to UpSampling2D.\n",
    "\n",
    "In the below, stride of (2,2) doubles the size (new values assume teh value 0), weight in the single filter is set to 1 (meaning input values are multipled by 1), bias is 0 meaning nothing is added to the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_5 (Conv2DTr (None, 4, 4, 1)           2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[1. 0. 2. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [3. 0. 4. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# example of using the transpose convolutional layer\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2DTranspose\n",
    "# define input data\n",
    "X = asarray([[1, 2],\n",
    "             [3, 4]])\n",
    "# show input data for context\n",
    "print(X)\n",
    "# reshape input data into one sample a sample with a channel\n",
    "X = X.reshape((1, 2, 2, 1))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv2DTranspose(1, (1,1), strides=(2,2), input_shape=(2, 2, 1)))\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# define weights that they do nothing\n",
    "weights = [asarray([[[[1]]]]), asarray([0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# make a prediction with the model\n",
    "yhat = model.predict(X)\n",
    "# reshape output to remove channel to make printing easier\n",
    "yhat = yhat.reshape((4, 4))\n",
    "# summarize output\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
